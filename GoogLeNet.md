# Going deeper with convolutions 更深的卷积

Christian Szegedy et al. Google Inc.

## Abstract

We propose a deep convolutional neural network architecture codenamed Inception, which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.

我们提出了一种深度卷积神经网络架构，代号Inception，在ILSVRC-14中获得了分类和检测的最好成绩。这个架构的主要特点是改进了网络内部计算资源的利用，在保持计算能力的预算不增加的同时，仔细设计出了更深更宽的网络。为了使质量得到最优化，架构设计是基于Hebbian原则和多尺度处理的直觉的。我们向ILSVRC-14提交的一个特殊版本称为GoogLeNet，是一个22层的深度网络，在分类和检测的任务中评估了其质量。

## 1 Introduction

In the last three years, mainly due to the advances of deep learning, more concretely convolutional networks [10], the quality of image recognition and object detection has been progressing at a dramatic pace. One encouraging news is that most of this progress is not just the result of more powerful hardware, larger datasets and bigger models, but mainly a consequence of new ideas, algorithms and improved network architectures. No new data sources were used, for example, by the top entries in the ILSVRC 2014 competition besides the classification dataset of the same competition for detection purposes. Our GoogLeNet submission to ILSVRC 2014 actually uses 12× fewer parameters than the winning architecture of Krizhevsky et al [9] from two years ago, while being significantly more accurate. The biggest gains in object-detection have not come from the utilization of deep networks alone or bigger models, but from the synergy of deep architectures and classical computer vision, like the R-CNN algorithm by Girshick et al[6].

在过去的三年中，由于深度学习（更具体来说是卷积网络[10]）的进展，图像识别和目标检测的效果得到了很大提升。其主要进步不是因为硬件更强大、数据集更大或模型更大，而主要是因为新的思想、算法和改进的网络架构，这很鼓舞人心。比如在ILSVRC-14中，除了在分类的数据集上的检测目的任务中，获奖的团队没有利用新的数据源。我们向ILSVRC-14提交的GoogLeNet的参数数量只是两年前获胜的Krizhevsky et al [9]架构的1/12，而准确率却得到了显著提高。目标检测方面最大的收获不是单单通过利用深度网络或更大的模型，而是深度模型和经典计算机视觉的协同作用，像Girshick et al[6]的R-CNN算法。

Another notable factor is that with the ongoing traction of mobile and embedded computing, the efficiency of our algorithms – especially their power and memory use – gains importance. It is noteworthy that the considerations leading to the design of the deep architecture presented in this paper included this factor rather than having a sheer fixation on accuracy numbers. For most of the experiments, the models were designed to keep a computational budget of 1.5 billion multiply-adds at inference time, so that the they do not end up to be a purely academic curiosity, but could be put to real world use, even on large datasets, at a reasonable cost.

另一个值得注意的因素是随着移动和嵌入式计算的不断牵引，我们算法的效率（尤其是能耗和内存使用）越来越重要，本文模型的深度框架的设计考虑包括了这个因素，而不是仅仅关注准确率的提升。对于大多数试验来说，设计的模型保持了推理时15亿次乘/加法的计算量，所以这最后没有成为纯粹的学术好奇试验，而可能放在真实世界的任务中使用，即使是在大型数据集，代价比较合理。

In this paper, we will focus on an efficient deep neural network architecture for computer vision, codenamed Inception, which derives its name from the Network in network paper by Lin et al [12] in conjunction with the famous “we need to go deeper” internet meme [1]. In our case, the word “deep” is used in two different meanings: first of all, in the sense that we introduce a new level of organization in the form of the “Inception module” and also in the more direct sense of increased network depth. In general, one can view the Inception model as a logical culmination of [12] while taking inspiration and guidance from the theoretical work by Arora et al [2]. The benefits of the architecture are experimentally verified on the ILSVRC 2014 classification and detection challenges, on which it significantly outperforms the current state of the art.

本文中我们聚焦在一种高效计算机视觉深度神经网络架构，代号Inception，名称来自Lin et al [12]的论文Network in network和著名的网络meme盗梦空间[1]。这里深度有两个不同的意思：首先我们新提出的Inception架构，而且更直接的意思是网络的深度增加了。总体来说，可以将Inception模型看做[12]的逻辑极限，而我们的理论指导是Arora et al [2]。这个架构的好处由ILSVRC-14的分类和检测挑战试验验证了，在那里我们比现有的最好成绩要好很多。

## 2 Related Work 相关工作

Starting with LeNet-5 [10], convolutional neural networks (CNN) have typically had a standard structure – stacked convolutional layers (optionally followed by contrast normalization and max-pooling) are followed by one or more fully-connected layers. Variants of this basic design are prevalent in the image classification literature and have yielded the best results to-date on MNIST, CIFAR and most notably on the ImageNet classification challenge [9, 21]. For larger datasets such as Imagenet, the recent trend has been to increase the number of layers [12] and layer size [21, 14], while using dropout [7] to address the problem of overfitting.

从LeNet-5[10]开始，卷积神经网络(CNN)一般都有一个标准结构，即堆栈式的卷积层（有的带有对比度归一化和max-pooling）后面跟着一个或几个全连接层。这种基本设计的变体在图像分类的文献中相当普遍，并在几个数据集上得到了目前最好的结果，包括MNIST, CIFAR和最著名的ImageNet分类挑战赛[9, 21]。对于大一些的数据集比如ImageNet，最近的趋势是增加层数[12]和层规模[21, 14]，同时用dropout[7]来解决过拟合的问题。

Despite concerns that max-pooling layers result in loss of accurate spatial information, the same convolutional network architecture as [9] has also been successfully employed for localization [9, 14], object detection [6, 14, 18, 5] and human pose estimation [19]. Inspired by a neuroscience model of the primate visual cortex, Serre et al.[15] use a series of fixed Gabor filters of different sizes in order to handle multiple scales, similarly to the Inception model. However, contrary to the fixed 2-layer deep model of [15], all filters in the Inception model are learned. Furthermore, Inception layers are repeated many times, leading to a 22-layer deep model in the case of the GoogLeNet model.

尽管担心max-pooling层会损失准确的空间信息，和[9]一样的卷积神经网络架构也在定位[9, 14]，目标检测[6, 14, 18, 5]和人体姿态估计[9]中成功得到了应用。由神经科学中的灵长目视觉皮层模型所启发，Serre et al.[15]使用了一系列不同尺寸的固定Garbor滤波器来处理多尺度问题，这与Inception模型类似。但与固定的2层深度模型[15]形成对比的是，Inception模型中的所有滤波器都是学习得到的。更进一步，Inception层重复了很多次，在GoogLeNet模型中模型深度达22。

Network-in-Network is an approach proposed by Lin et al. [12] in order to increase the representational power of neural networks. When applied to convolutional layers, the method could be viewed as additional 1×1 convolutional layers followed typically by the rectified linear activation [9]. This enables it to be easily integrated in the current CNN pipelines. We use this approach heavily in our architecture. However, in our setting, 1 × 1 convolutions have dual purpose: most critically, they are used mainly as dimension reduction modules to remove computational bottlenecks, that would otherwise limit the size of our networks. This allows for not just increasing the depth, but also the width of our networks without significant performance penalty.

Lin et al. [12]提出Network-in-Network模型来增强神经网络的表示能力。当应用在卷积层中时，这个方法可以看做是，额外的1×1卷积层后跟着ReLU激活函数[9]。这使其很容易整合到目前的CNN架构流水线中。我们的架构中很多地方都用了这种方法。但是在我们的设置中，1×1卷积有双重目的，最主要用作降维模块，来去除计算瓶颈，如果不这样，就会限制我们模型的规模。这不仅可以增加模型深度，还可以网络宽度，而且不会显著增加计算量。

The current leading approach for object detection is the Regions with Convolutional Neural Networks (R-CNN) proposed by Girshick et al. [6]. R-CNN decomposes the overall detection problem into two subproblems: to first utilize low-level cues such as color and superpixel consistency for potential object proposals in a category-agnostic fashion, and to then use CNN classifiers to identify object categories at those locations. Such a two stage approach leverages the accuracy of bounding box segmentation with low-level cues, as well as the highly powerful classification power of state-of-the-art CNNs. We adopted a similar pipeline in our detection submissions, but have explored enhancements in both stages, such as multi-box [5] prediction for higher object bounding box recall, and ensemble approaches for better categorization of bounding box proposals.

目前领先的目标检测方法是Girshick et al. [6]提出的R-CNN(Regions with Convolutional Neural Networks)。R-CNN将检测问题分解成两个子问题：首先使用低级线索如色彩和超像素连贯性进行潜在的目标建议，在不知道类别的情况下进行，然后使用CNN分类器在这些区域识别目标类别。这种两阶段方法将边界框分割的准确性与底层线索和最先进的CNN的强大的分类能力结合起来，提高了模型了性能。我们在检测任务中采用了类似的流水线结构，但在两个阶段都进行了改进，比如对于更高的边界框联想使用多边界框[5]预测，组合各种方法得到更好的边界框建议分类。

## 3 Motivation and High Level Considerations 动机和高层考虑

The most straightforward way of improving the performance of deep neural networks is by increasing their  size. This includes both increasing the depth – the number of levels – of the network and its width: the number of units at each level. This is as an easy and safe way of training higher quality models, especially given the availability of a large amount of labeled training data. However this simple solution comes with two major drawbacks.

深度神经网络改进性能最直接的方法就是增加规模，这包括增加网络深度（层数）和宽度（每层的单元数目）。这是训练更高质量模型的简单安全的方法，尤其是有大量标记训练数据可用时。但是这种简单的方法却又两个主要的缺陷。

Bigger size typically means a larger number of parameters, which makes the enlarged network more prone to overfitting, especially if the number of labeled examples in the training set is limited. This can become a major bottleneck, since the creation of high quality training sets can be tricky and expensive, especially if expert human raters are necessary to distinguish between fine-grained visual categories like those in ImageNet (even in the 1000-class ILSVRC subset) as demonstrated by Figure 1.

更大的规模通常都意味着参数更多，这使得这个增大的网络更加容易过拟合，尤其是当训练集中的标记样本数量有限时。这可能成为主要瓶颈，因为高质量训练集的获得通常很难，代价很大，尤其是如果需要专家打分人员来区分细粒度视觉类别图像，比如图1所示的ImageNet图像（1000类的ILSVRC子集也很难）。

Figure 1: Two distinct classes from the 1000 classes of the ILSVRC 2014 classification challenge. (a) Siberian husky (b) Eskimo dog

图1. ILSVRC-14分类挑战赛1000类中的两个不同类别。(a)西伯利亚哈士奇；(b)爱斯基摩狗

Another drawback of uniformly increased network size is the dramatically increased use of computational resources. For example, in a deep vision network, if two convolutional layers are chained, any uniform increase in the number of their filters results in a quadratic increase of computation. If the added capacity is used inefficiently (for example, if most weights end up to be close to zero), then a lot of computation is wasted. Since in practice the computational budget is always finite, an efficient distribution of computing resources is preferred to an indiscriminate increase of size, even when the main objective is to increase the quality of results.

模型增大的另一个问题是急剧增加的计算需求。比如，在深度视觉网络中，如果两个卷积层连在一起，任何滤波器大小的统一增加都会导致运算量平方式的增加。如果增加的容量没有充分使用（比如，如果多数权重都很接近0），那么就会浪费很多计算量。由于在实践中计算量预算永远是有限的，即使我们的主要目标是增加分类结果质量，那么我们也倾向于计算资源的有效分配，而不是随意增加模型规模。

The fundamental way of solving both issues would be by ultimately moving from fully connected to sparsely connected architectures, even inside the convolutions. Besides mimicking biological systems, this would also have the advantage of firmer theoretical underpinnings due to the ground-breaking work of Arora et al. [2]. Their main result states that if the probability distribution of the data-set is representable by a large, very sparse deep neural network, then the optimal network topology can be constructed layer by layer by analyzing the correlation statistics of the activations of the last layer and clustering neurons with highly correlated outputs. Although the strict mathematical proof requires very strong conditions, the fact that this statement resonates with the well known Hebbian principle – neurons that fire together, wire together – suggests that the underlying idea is applicable even under less strict conditions, in practice.

解决这两个问题的根本方法是，彻底从全连接的架构，转向稀疏连接的架构，即使在卷积层内也要如此。除了是要模仿生物系统，这还有更坚实的理论支持，就是Arora et al. [2]的工作，其主要结论是，如果数据集的概率分布可以由一个大的很稀疏的深度神经网络表示的话，那么最佳网络拓扑可以以如下的方式构建，分析当前层激活的统计相关性，对具有高度相关性输出的神经元进行聚类，并确定下一层的结构。虽然严格的数学证明需要很强的假设条件，但这个结论与著名的Hebbian原则不谋而合，即一起放电的神经元，其连接也会增强，这说明其基本思想即使在没那么严格的条件下，也是可以在实践中应用的。

On the downside, todays computing infrastructures are very inefficient when it comes to numerical calculation on non-uniform sparse data structures. Even if the number of arithmetic operations is reduced by 100×, the overhead of lookups and cache misses is so dominant that switching to sparse matrices would not pay off. The gap is widened even further by the use of steadily improving, highly tuned, numerical libraries that allow for extremely fast dense matrix multiplication, exploiting the minute details of the underlying CPU or GPU hardware [16, 9]. Also, non-uniform sparse models require more sophisticated engineering and computing infrastructure. Most current vision oriented machine learning systems utilize sparsity in the spatial domain just by the virtue of employing convolutions. However, convolutions are implemented as collections of dense connections to the patches in the earlier layer. ConvNets have traditionally used random and sparse connection tables in the feature dimensions since [11] in order to break the symmetry and improve learning, the trend changed back to full connections with [9] in order to better optimize parallel computing. The uniformity of the structure and a large number of filters and greater batch size allow for utilizing efficient dense computation.

不幸的是，今天的计算基础设施对于非一致稀疏数据结构的数值计算是非常低效的。即使算数操作数量减少到1/100，用于查找和缓存未命中的开销仍然非常大，转换到稀疏矩阵仍然不划算。当使用持续改进的、高度调谐的数值计算库，而这个库允许极快的稠密矩阵乘法，压榨潜在的CPU和GPU硬件的计算资源的微小细节时，这个不划算的差距会进一步拉大[16, 9]。同时，非一致稀疏模型需要更复杂的工程和计算基础设施。多数现在的视觉相关的机器学习系统在空间域使用稀疏性只是因为要进行卷积。但是，前一层图像块的稠密连接的集合才是卷积运算。ConvNets传统上从[11]才在特征维度开始使用随机稀疏的连接，为的是要打破对称性，改善学习，而这个趋势又从[9]改回了全连接，因为要更好的优化并行计算。结构的一致性，大量滤波器，更大的batch size都需要采用有效的稠密计算。

This raises the question whether there is any hope for a next, intermediate step: an architecture that makes use of the extra sparsity, even at filter level, as suggested by the theory, but exploits our current hardware by utilizing computations on dense matrices. The vast literature on sparse matrix computations (e.g. [3]) suggests that clustering sparse matrices into relatively dense submatrices tends to give state of the art practical performance for sparse matrix multiplication. It does not seem far-fetched to think that similar methods would be utilized for the automated construction of non-uniform deep-learning architectures in the near future.

这提出了如下的问题，是否可能有下一个间接的步骤：这个架构利用了额外的稀疏性，即使在滤波器层，像理论建议的那样，但利用现有硬件的方式是稠密矩阵的计算。关于稀疏矩阵计算有很多文献如[3]，建议将稀疏矩阵分成相对稠密的子矩阵，有助于在稀疏矩阵乘法运算中得到最佳工程性能。在不远的将来，类似的方法可以用于非一致深度学习框架的自动构建，这个想法好像不是那么异想天开。

The Inception architecture started out as a case study of the first author for assessing the hypothetical output of a sophisticated network topology construction algorithm that tries to approximate a sparse structure implied by [2] for vision networks and covering the hypothesized outcome by dense, readily available components. Despite being a highly speculative undertaking, only after two iterations on the exact choice of topology, we could already see modest gains against the reference architecture based on [12]. After further tuning of learning rate, hyperparameters and improved training methodology, we established that the resulting Inception architecture was especially useful in the context of localization and object detection as the base network for [6] and [5]. Interestingly, while most of the original architectural choices have been questioned and tested thoroughly, they turned out to be at least locally optimal.

Inception架构第一个开始进行这样的研究，尝试构建一个复杂网络拓扑，得到的网络试图近似一个[2]中的视觉网络稀疏矩阵，其近似结果是稠密的可用组件，就像上面阐述的那样。尽管这一切都是假设，但在拓扑结构的选择上只经过2次迭代，我们已经看到了一定的收获，相对于[12]中的参考架构。在进一步调整了学习速率、超参数，改进了训练方法后，我们确定得到的Inception架构对于定位、目标检测都非常有用，可以作为[6]和[5]的基础网络架构。有意思的是，大多数原有的架构选择已经经过彻底的拷问和测试，它们只能算是局部最优的。

One must be cautious though: although the proposed architecture has become a success for computer vision, it is still questionable whether its quality can be attributed to the guiding principles that have lead to its construction. Making sure would require much more thorough analysis and verification: for example, if automated tools based on the principles described below would find similar, but better topology for the vision networks. The most convincing proof would be if an automated system would create network topologies resulting in similar gains in other domains using the same algorithm but with very differently looking global architecture. At very least, the initial success of the Inception architecture yields firm motivation for exciting future work in this direction.

人必须要谨慎：虽然提出的架构已经在计算机视觉方面很成功，但仍然可以质疑，其质量是否达到了构建原则中的理想效果？做这样的确认需要非常多的彻底分析和验证：比如，如果基于这种原则的自动工具（如下述）可以找到视觉网络的类似但更好的拓扑结构怎么办？最有说服力的证据是，如果自动系统可以生成的网络拓扑，在其他领域结果类似，使用的也是一样的算法，但全局架构很不一样。至少，Inception架构最初的成功一定会激励出更多这个方向的工作。

## 4 Architectural Details 架构细节

The main idea of the Inception architecture is based on finding out how an optimal local sparse structure in a convolutional vision network can be approximated and covered by readily available dense components. Note that assuming translation invariance means that our network will be built from convolutional building blocks. All we need is to find the optimal local construction and to repeat it spatially. Arora et al. [2] suggests a layer-by layer construction in which one should analyze the correlation statistics of the last layer and cluster them into groups of units with high correlation. These clusters form the units of the next layer and are connected to the units in the previous layer. We assume that each unit from the earlier layer corresponds to some region of the input image and these units are grouped into filter banks. In the lower layers (the ones close to the input) correlated units would concentrate in local regions. This means, we would end up with a lot of clusters concentrated in a single region and they can be covered by a layer of 1×1 convolutions in the next layer, as suggested in [12]. However, one can also expect that there will be a smaller number of more spatially spread out clusters that can be covered by convolutions over larger patches, and there will be a decreasing number of patches over larger and larger regions. In order to avoid patch-alignment issues, current incarnations of the Inception architecture are restricted to filter sizes 1×1, 3×3 and 5×5, however this decision was based more on convenience rather than necessity. It also means that the suggested architecture is a combination of all those layers with their output filter banks concatenated into a single output vector forming the input of the next stage. Additionally, since pooling operations have been essential for the success in current state of the art convolutional networks, it suggests that adding an alternative parallel pooling path in each such stage should have additional beneficial effect, too (see Figure 2(a)).

Figure 2: Inception module (a) Inception module, naive version (b) Inception module with dimension reductions

As these “Inception modules” are stacked on top of each other, their output correlation statistics are bound to vary: as features of higher abstraction are captured by higher layers, their spatial concentration is expected to decrease suggesting that the ratio of 3×3 and 5×5 convolutions should increase as we move to higher layers.

One big problem with the above modules, at least in this na¨ ıve form, is that even a modest number of 5×5 convolutions can be prohibitively expensive on top of a convolutional layer with a large number of filters. This problem becomes even more pronounced once pooling units are added to the mix: their number of output filters equals to the number of filters in the previous stage. The merging of the output of the pooling layer with the outputs of convolutional layers would lead to an inevitable increase in the number of outputs from stage to stage. Even while this architecture might cover the optimal sparse structure, it would do it very inefficiently, leading to a computational blow up within a few stages.

This leads to the second idea of the proposed architecture: judiciously applying dimension reductions and projections wherever the computational requirements would increase too much otherwise. This is based on the success of embeddings: even low dimensional embeddings might contain a lot of information about a relatively large image patch. However, embeddings represent information in a dense, compressed form and compressed information is harder to model. We would like to keep our representation sparse at most places (as required by the conditions of [2]) and compress the signals only whenever they have to be aggregated en masse. That is, 1×1 convolutions are used to compute reductions before the expensive 3×3 and 5×5 convolutions. Besides being used as reductions, they also include the use of rectified linear activation which makes them dual-purpose. The final result is depicted in Figure 2(b).

In general, an Inception network is a network consisting of modules of the above type stacked upon each other, with occasional max-pooling layers with stride 2 to halve the resolution of the grid. For technical reasons (memory efficiency during training), it seemed beneficial to start using Inception modules only at higher layers while keeping the lower layers in traditional convolutional fashion. This is not strictly necessary, simply reflecting some infrastructural inefficiencies in our current implementation.

One of the main beneficial aspects of this architecture is that it allows for increasing the number of units at each stage significantly without an uncontrolled blow-up in computational complexity. The ubiquitous use of dimension reduction allows for shielding the large number of input filters of the last stage to the next layer, first reducing their dimension before convolving over them with a large patch size. Another practically useful aspect of this design is that it aligns with the intuition that visual information should be processed at various scales and then aggregated so that the next stage can abstract features from different scales simultaneously.

The improved use of computational resources allows for increasing both the width of each stage as well as the number of stages without getting into computational difficulties. Another way to utilize the inception architecture is to create slightly inferior, but computationally cheaper versions of it. We have found that all the included the knobs and levers allow for a controlled balancing of computational resources that can result in networks that are 2−3× faster than similarly performing networks with non-Inception architecture, however this requires careful manual design at this point.

## 5 GoogLeNet