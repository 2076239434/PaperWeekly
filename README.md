# PaperWeekly

The meaning of translation is to read, slowly, with concentration, to understand.

## Deep learning models and algorithms

Model name | Published time | arxiv link
--- | --- | ---
AlexNet | 2012 | [nips link](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
Visualization | 2013 | [1311.2901](https://arxiv.org/abs/1311.2901)
Inception V1 i.e. GoogLeNet | 2014 | [1409.4842v1](https://arxiv.org/abs/1409.4842v1)
Inception V2 | 2015 | [1502.03167v3](https://arxiv.org/abs/1502.03167v3)
Inception V3 | 2015 | [1512.00567v3](https://arxiv.org/abs/1512.00567v3)
Inception V4 | 2016 | [1602.07261v2](https://arxiv.org/abs/1602.07261v2)
Xception     | 2016 | [1610.02357v3](https://arxiv.org/abs/1610.02357v3)
VGG | 2014 | [1409.1556](https://arxiv.org/abs/1409.1556)
ResNet V1 | 2015 | [1512.03385](https://arxiv.org/abs/1512.03385)
FaceNet | 2015 | [1503.03832](https://arxiv.org/abs/1503.03832)
MobileNet | 2017 | [1704.04861](https://arxiv.org/abs/1704.04861)
MobileNetV2 | 2018 | [1801.04381v3](https://arxiv.org/abs/1801.04381v3)

## Object Detetion models and algorithms

Model name | Published time | arXiv link
--- | --- | ---
SelectiveSearch | 2012 | [personal link](www.huppelen.nl/publications/selectiveSearchDraft.pdf)
R-CNN | 2014 | [1311.2524v5](https://arxiv.org/abs/1311.2524v5)
Fast R-CNN | 2015 | [1504.08083v2](https://arxiv.org/abs/1504.08083v2)
Faster R-CNN | 2016 | [1506.01497](https://arxiv.org/abs/1506.01497)
Mask R-CNN | 2018 | [1703.06870v3](https://arxiv.org/abs/1703.06870v3)
SSD | 2016 | [1512.02325v5](https://arxiv.org/abs/1512.02325v5)
Speed/accuracy trade-offs | [1611.10012v3](https://arxiv.org/abs/1611.10012v3)
YOLOv1 | 2015 | [1506.02640](https://arxiv.org/abs/1506.02640)
YOLO9000 | 2016 | [1612.08242](https://arxiv.org/abs/1612.08242)
YOLOv3 | 2018 | [1804.02767](https://arxiv.org/abs/1804.02767)

## Datasets

Datasets name | Published time | arXiv link
--- | --- | ---
MS COCO | 2014 | [1405.0312](https://arxiv.org/abs/1405.0312)
CrowdHuman | 2018 | [1805.00123](https://arxiv.org/abs/1805.00123)

## Books:

1. [深度学习入门：基于Python的理论与实现](http://www.ituring.com.cn/book/1921)
2. [解析卷积神经网络—深度学习实践手册](http://lamda.nju.edu.cn/weixs/book/CNN_book.html)

## Links:

1. [Keras](https://keras.io/zh/)
2. [movidius](https://developer.movidius.com/)
3. [feature map](https://stats.stackexchange.com/questions/291820/what-is-the-definition-of-a-feature-map-aka-activation-map-in-a-convolutio)
4. [tensorflow dataset](https://www.tensorflow.org/guide/datasets)
5. [tensorflow estimator](https://www.tensorflow.org/guide/estimators)
6. [tensorflow low level api - Intro](https://www.tensorflow.org/guide/low_level_intro)
7. [tensorflow low level api - Tensors](https://www.tensorflow.org/guide/tensors)
8. [tensorflow low level api - Variables](https://www.tensorflow.org/guide/variables)
9. [tensorflow low level api - Graphs and Sessions](https://www.tensorflow.org/guide/graphs)
10. [tensorflow low level api - Save and Restore](https://www.tensorflow.org/guide/saved_model)
11. [tensorflow low level api - Control Flow](https://www.tensorflow.org/guide/autograph)
12. [caffe tutorial net-layer-blob](http://caffe.berkeleyvision.org/tutorial/net_layer_blob.html)
13. [caffe tutorial forward-backward](http://caffe.berkeleyvision.org/tutorial/forward_backward.html)
14. [caffe tutorial loss](http://caffe.berkeleyvision.org/tutorial/loss.html)
15. [caffe tutorial solver](http://caffe.berkeleyvision.org/tutorial/loss.html)
16. [caffe tutorial layers](http://caffe.berkeleyvision.org/tutorial/layers.html)